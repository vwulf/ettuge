[^1] is the best introduction to λ calculus I have seen.

⍵ or loop = (λ.x x x) (λ.x x x)

If Y given f, x is is written as f( f (x)) and x is substituted by f(x), we have recursion.

Y f x = f(f(f(.... (f(x))))

//  Y combinator
Y = λ.f (λ.x f (x x)) (λ.x f (x x))
=> λ.f (λ.x f ((λ.x f (x x)) (λ.x f (x x)))) 
=>  λ.f (λ.x f (f (λ.x f (x x)) (λ.x f (x x))))
=> λ.f (λ.x f (f (λ.x f ((λ.x f (x x)) (λ.x f (x x))))))
...

Y f x = f (f x)

I had encountered fixed points in compiler backend code - primarily to eliminate cycles in graphs.
My introduction to functional programming was though Lisp in compiler and AI classes, later scheme and then
ML for an undergraduate course on programming languages where I wrote frontends astonishingly easily in ML
(OCaml without any of the Object parts). I went on to TA an undergraduate CS honors programming language course
which taught LISP, Scheme and Haskell. Haskell remained completely opaque to me although I graded coursework and such.

I forgot all about it and got back to my home of C++ which I had spent half a decade by then and programmed C++ professionally
for another half a decade. In the course of work, I chanced upon Python (which seemed much cleaner than the Perl I had done in
an internship). When I saw list and dictionary comprehensions - esp nested ones, I was sold over the expressiveness.
I did some side projects in python and moved to a startup where I wanted to build a management plane in python.
Another colleauge was dead set against python and explained the problems of the Global Interpreter Lock (GIL) and how multithreading
is a joke of sorts. He wanted to build around the JVM stack. He asked me to look at Scala which has similar expressiveness to python
and was JVM based giving options to back out if needed. I protoptyped the first section of scala code for the startup and the scala
stack grew to become the entire management plane.

In the course of learning scala, the model of functional programming I thought I knew and what was needed was something else.
I had almost no insights into category theory when I did functional programming in the past - which explained my difficulties with haskell.

For the project I moved from exception based stack to eschewing exceptions by turning them to Options. Later I discovered scalaz and its Validation
and preferred that to the default Either due to the more intutitive bias of Validation and the more principled design of scalaz.
However I had quite a few struggles with the usage of ValidationNel and the way errors were combined. The use case that I had was very different
from the usecase of ValidationNel. ValidationNel was great for getting list of all errors when doing a bunch of operations but not a bunch of
partial successes. I kept operator chasing to get my usecase done before I realized that I needed to understand the space comprehensively.
At the same time another portion of the stack started using twitter futures and monadic composition.

At this time, I went through all of [^13] in parallel to [^12] to understand functors, applicatives, monoids and monads. After I went through
the whole thing, it seemed straight forward in retrospective but it was quite a learning curve.



Later I had encountered recursion schemes through this fantastic talk by tpolecat [^11]. This was much
after extensive stumbling around functional programming in scalaz [^12] years after grad school projects
writing compiler frontends in ocaml. 

If you remember this there was a practical reason to do some research on lambda calculus (postfix)
for a usecase I had, I chanced upon the De bruijn index: [^5]

From which I translated the pun:
ಏಕೆ = [ [೧ (೦ ೦)] [೧ (೦ ೦)] ]
Eke = [ [1 (0 0)] [1 (0 0)] ]

In the standard form,
Y = λf. (λx. f (x x)) λx. f (x x)

can be written as:
ಏಕೆ = ॐಅ . (ॐಉ . ಅ (ಉ ಉ)) ॐಉ . ಅ (ಉ ಉ)
Eke = Om a . (Om u . a (u u)) Om u . a (u u)
Without any semantic change.

Haskell uses \ for λ and -> for .

Pretty cool to use as a basis for any generative language.

If that’s too abstract, see this [^2]
To see how easily program structure is derived from lambda calculus.

It's very tempting to state that λ calculus is a great start for a small programming language.
However it's small but not easy to use.

[^1]: https://youtu.be/eis11j_iGMs?si=sM5lTjltqQrGGfPN
[^2]: https://github.com/andrejbauer/plzoo/blob/master/src/lambda/example.lambda
[^3]: https://www.youtube.com/watch?v=43XaZEn2aLc&list=PL1a1q1zrmyEwpA2PvYcM1UqE18zekujW-&index=17
[^4]: https://github.com/vwulf/ettuge/blob/master/src/main/md/kannada/Eke.md
[^5]: https://loup-vaillant.fr/articles/programming-ring
[^6]: https://dev.to/dannypsnl/de-bruijn-index-why-and-how-32f6
[^7]: https://cs.stackexchange.com/questions/109954/writing-a-grammar-for-lambda-calculus
[^8]: https://youtu.be/09-9LltqWLY?si=CJ1TbuAjvMGPwUX8
[^9]: https://www.youtube.com/watch?v=43XaZEn2aLc&list=PL1a1q1zrmyEwpA2PvYcM1UqE18zekujW-&index=17
[^10]: https://cs.stackexchange.com/questions/109954/writing-a-grammar-for-lambda-calculus
[^11]: https://www.youtube.com/watch?v=XHiTK4UOIf0
[^12]: http://eed3si9n.com/learning-scalaz/
[^13]: https://learnyouahaskell.com/
